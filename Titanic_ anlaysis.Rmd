---
title: "Titanic_analysis"
author: "Calvin"
date: "11/08/2021"
output: html_document
---

# Goal

The goal of this analysis is to analyze what type of passenger are more
likely to survive base on list of features and build a predictive model
to make prediction.


```{r loading package}

library(tidyverse) # data cleaning and manipulation
library(ggplot2) # ggplot
library("EnvStats")
library(rpart) # for fitting decision trees
library(rpart.plot) #for plotting decision trees
library(coin) # mood median test
library(randomForest) # for random forest model building

# library("caret") # Use to split data (i.e training set and test set)

```


```{r loading data}

# read data
original.titanic.train <- read.csv("train.csv")
original.titanic.test <- read.csv("test.csv")

# Make a temporary copy
titanic.train <- original.titanic.train
titanic.test <- original.titanic.test

# Check each variable type and what data looks like
str(titanic.train)
str(titanic.test)

```

```{r cleaning data}

# Convert some variables to proper type

titanic.train$Survived <- as.factor(titanic.train$Survived)
titanic.train$Pclass <- as.factor(titanic.train$Pclass)

# check missing values
colSums(is.na(titanic.train))
colSums(titanic.train== "")

#fill mode value to Embarked

table(titanic.train$Embarked)
subset(titanic.train, Embarked == "")
titanic.train[c(62,830),]$Embarked <- "S"

# Split first letter of "Cabin" 
with_cabin <- subset(titanic.train, Cabin != "")
cabin_vector <- with_cabin$Cabin
str_split(cabin_vector,pattern="",n=2) -> cabin_list
cabin_letterlist <- c()
j <- 1

for (i in cabin_list){
  cabin_letterlist[j] <- i[1]
  j <- j+1
}

with_cabin$Cabin_letter <- cabin_letterlist

# Merge data back to titanic set

merge(titanic.train,with_cabin, all = TRUE) -> titanic.train
```


```{r predict missing age using lm model with other features}

# Use row with non-null Age value to predict the remaining missing Age values

with_age <- subset(titanic.train, !(is.na(Age)) )
no_age <- subset(titanic.train, (is.na(Age)))


# select potential features for predictor

age_predictor <- lm(Age~ Survived + Pclass + Sex + SibSp + Parch + Fare + Embarked, data = with_age)

summary(age_predictor)

# By Backward model selection

# delete Sex

age_predictor <- lm(Age~ Survived + Pclass + SibSp + Parch + Fare + Embarked, data = with_age)

summary(age_predictor)

# delete Parch

age_predictor <- lm(Age~ Survived + Pclass + SibSp  + Fare + Embarked, data = with_age)

summary(age_predictor)

# delete Embarked

age_predictor <- lm(Age~ Survived + Pclass + SibSp  + Fare, data = with_age)

summary(age_predictor)

# All variables are statistically significant, use above model to predict missing age
predicted_age <- predict(age_predictor, newdata = no_age)
no_age$Age <- predicted_age

# Merge and rearrange data
titanic.train <- rbind(no_age,with_age)
titanic.train <- arrange(titanic.train, PassengerId)
```


# Analysis, analyze Survived vs other features

```{r number of Survived, echo=TRUE}

titanic.survive1 <- titanic.train %>% filter(Survived == 1) 
titanic.survive0 <- titanic.train %>% filter(Survived == 0)

titanic.train %>% group_by(Survived) %>% summarize(count = n()) %>%
  mutate(Proportion = prop.table(count))

titanic.train %>% ggplot(., aes(x=Survived, fill=Survived)) + geom_bar() + 
  labs(title="Number of Survived \n",subtitle ="0 = Not Survived \n1 = Survived")

```


```{r Survived vs Gender, echo=TRUE}

# table count survive by gender

titanic.train %>% group_by(Survived,Sex)  %>%  
  summarize(count = n()) %>% mutate(Proportion_Survived = prop.table(count))

gender_table <- table(titanic.train$Survived,titanic.train$Sex)
male_total <-sum(gender_table[1,2],gender_table[2,2])
female_total <-sum(gender_table[1,1],gender_table[2,1])

# Visualization

titanic.train %>% ggplot(., aes(x=Survived, fill=Sex)) + geom_bar() +
labs(title="Survived vs Gender \n",subtitle ="0 = Not Survived \n1 = Survived")

titanic.train %>% ggplot(., aes(x=Survived, fill=Survived)) + geom_bar() + facet_wrap(~Sex) +
labs(title="Survived vs Gender \n",subtitle ="0 = Not Survived \n1 = Survived")

# chi-square test

chisq.test(titanic.train$Survived, titanic.train$Sex)

# The result p-value = 2.2e-16, we can reject null hypothesis and conclude there's
# association between survived and gender.

# Odd Ratio

gender_OR <- (gender_table[1,1]/gender_table[1,2])/(gender_table[2,1]/gender_table[2,2])

# The odd ratio is 12.35, the odd of female Survived is 12 times than the odd of male Survived.

# Relative Risk

gender_RR <- (gender_table[2,2]/male_total)/(gender_table[2,1]/female_total)

# The risk of being a male is 3.14 times more than being a female.

# Conclusion: 
# Female are much more likely to survived in Titanic scenario.
```

```{r Survived vs Pclass, echo=TRUE}

# Pclass vs Suvive count and proportion of Pclass for two group Survive = 1 , Survive = 0 
titanic.train %>% group_by(Survived, Pclass) %>% summarize(count = n()) %>%   
  mutate(Proportion_Survived = prop.table(count))

# Visualizaiton Pclass vs Survived

titanic.train %>% ggplot(., aes(x=Pclass, fill=Survived)) + geom_bar(position = "fill") +
  labs(title="Survived vs Pclass and Gender \n",subtitle ="0 = Not Survived \n1 = Survived")

# By observation, pClass seems to have association with Survived. But we also want to take
# gender into account.


# Visualizaiton Pclass,Gender vs Survived

titanic.train %>% ggplot(., aes(x=Sex, fill=Survived)) + geom_bar() + facet_wrap(~Pclass) +
  labs(title="Survived vs Pclass and Gender \n",subtitle ="0 = Not Survived \n1 = Survived")

# By observation, pClass seems to have association with Survived. But we also want to take
# gender into account.

# proportion of Gender in each Pclass

titanic.train %>% group_by(Pclass,Sex) %>%
  summarize(count = n()) %>% mutate(Proportion_Pclass = prop.table(count))

# chi-square test with fixed gender, test whethere Pclass associated with Survived

titanic.train %>% filter(Sex == "male") -> titanic.male
chisq.test(x=titanic.male$Survived, y = titanic.male$Pclass)

titanic.train %>% filter(Sex == "female") -> titanic.female
chisq.test(x=titanic.female$Survived, y = titanic.female$Pclass)

# Both test's result reject null hypothesis and we can conclude there's association between
# Pclass and Survived.


```
```{r Survived vs Age}

# Box-plot visualization

titanic.train %>% ggplot(., aes(x=Survived,y=Age)) + geom_boxplot()

# t-test, two set are fairly normal distribution
t.test(titanic.survive1$Age,titanic.survive0$Age)

# The result reject null hypothesis, conclude that the Age difference between
# Survived and not Survived is (0.42, 4.18)

```

```{r Survived vs Fare}

# Box-plot visualization

titanic.train %>% ggplot(., aes(x=Survived,y=Fare)) + geom_boxplot()
# It seems like two group have different mean/median, need further analysis
# Also, the data present some outliers that result skewed data.

boxplot(titanic.train$Fare~titanic.train$Survived, xlab="Survived", ylab="Fare")$out
# 71 outlier are present, this is roughly 8% of the data, we cannot simply exclude them.

# We will do mood median test to see if median difference are significant
median_test(Fare~Survived, data=titanic.train)

# The result of test reject null hypothesis and conclude there's difference in median.

# Additionally, we can take samples from two distribution to see if mean of sample average 
# are different

sample_fare_survive1 <- c()
sample_fare_survive0 <- c()

# Sample from two different group (Survived = 1 or 0)
for (i in 1:100){
   sample_fare_survive1[i] <- mean(sample(titanic.survive1$Fare, size = 100))
   sample_fare_survive0[i] <- mean(sample(titanic.survive0$Fare, size = 100))
}


# By central limit theorem, distribution of sample average is normal, we can use t-test
t.test(sample_fare_survive1,sample_fare_survive0)

# The result reject null hypothesis and conclude the sample average are different between
# two groups, which means Survived are associated with Fare.


# Conclusion:
# Fare are associated with Survived

```

```{r Survived vs Cabin}

# Test if first Cabin letter associate with Survived
chisq.test(x = titanic.train$Cabin_letter,titanic.train$Survived)

# The result do not reject null hypothesis, we can not conclude there's association.
# It would not be a realiable feature.

```

```{r Survived vs Embarked}

chisq.test(titanic.train$Embarked,titanic.train$Survived)

# The result reject null hypothesis and conclude there's association.

chisq.test(titanic.train$Embarked,titanic.train$Survived)
chisq.test(titanic.train$Embarked,titanic.train$Pclass)

titanic.train %>% ggplot(., aes(x=Embarked,fill=Survived)) + geom_bar(position="fill") +
  labs(title = "Survived vs Embarked")
  

# From observation, Embarked is associated with Survived, Embarked at Port C
# is significant higher than at Port Q and S.


# Check Pclass proportion at each Port

titanic.train %>% ggplot(., aes(x=Embarked,fill=Pclass)) + geom_bar(position = "fill") +
  facet_wrap(~Survived)

# People embarked at port C are mostly in first class. This is very likely the reason why
# embarked at port C have significant higher chance to survive.
```

# Building Model

Use 3 different classification method to predict survive based on relevant features above

```{r clean test data}
str(titanic.test)

# Similarly need to clean test dataset as how we clean train dataset

# Convert some variables to proper type

titanic.test$Pclass <- as.factor(titanic.test$Pclass)

# check missing values
colSums(is.na(titanic.test))
colSums(titanic.train== "")

# predict age for test set

titanic.test %>% filter(is.na(Age)) -> test_no_age
titanic.test %>% filter(!(is.na(Age))) -> test_with_age

# Backward model selection
test_age_predict <- lm(Age ~ Pclass + SibSp, data=titanic.test)
test_predicted.age <- predict(test_age_predict, newdata = test_no_age)
test_no_age$Age <- test_predicted.age

# Merge two set and rearrange
titanic.test <- rbind(test_no_age,test_with_age)
titanic.test <- arrange(titanic.test, PassengerId)

# Fill median value to missing Fare
titanic.test %>% filter(is.na(Fare))
titanic.test[titanic.test$PassengerId==1044,]$Fare <- median(titanic.test$Fare, na.rm=TRUE)



```


```{r Logistic Regression Model}

# Logistic model, use relevant feature and 
# variable are selected by backward model selection
pred_log.model <- glm(Survived ~ Sex + SibSp + Age + Pclass + Embarked,
                      data = titanic.train, family = "binomial")
summary(pred_log.model)

# predict result using above model
log_result <- predict(pred_log.model,newdata = titanic.test, type = "response")

# Merge passengerID and predicted Survived
output <- data.frame(PassengerId = original.titanic.test$PassengerId)
output$Survived <- log_result
output$Survived <- ifelse(output$Survived > 0.5, 1, 0)

write.csv(output, file= "Titanic_logistic_prediction.csv", row.names=FALSE)

# Logistic regression Accuracy Result: 75.83%

```

```{r decision tree}
# decision tree model using relevant features
decision_tree <- rpart(Survived ~Sex + SibSp + Age + Pclass + Fare + Embarked, 
                       data = titanic.train, cp = 0.001)
# cp control the complexity of the tree, default = 0.01

# Visualization of tree
prp(decision_tree)

# predict whether survived
decision_result <- predict(decision_tree, newdata = titanic.test)

# Merge data
output2 <- data.frame(PassengerId = original.titanic.test$PassengerId)
output2$Survived <- decision_result[,2]
output2$Survived <- ifelse(output2$Survived > 0.5, 1, 0)

write.csv(output2, file= "Titanic_decision_tree_prediction.csv", row.names=FALSE)

# Decision Tree Accuracy Result: 74.40%

```



```{r random forest}

# Fix computing issue for random forest
titanic.train$Embarked <- factor(titanic.train$Embarked, 
                                 levels = c("S","Q","C"),
                                 labels = c("S","Q","C")
                                 )

# random forest model using relevant feature
random_forest_model <- randomForest(Survived ~ Sex + Pclass + Fare + Embarked + SibSp + Age,
                                    data = titanic.train, 
                                    ntree = 1000, # ntree = number of trees to grow
                                    mtry=3) #  mtry = number of features to choose for bootstrap
                                            #  sample

random_forest_result <- predict(random_forest_model, 
                                newdata = titanic.test,
                                type="class")

# Merge data
output3 <- data.frame(PassengerId = original.titanic.test$PassengerId)
output3$Survived <- random_forest_result

write.csv(output3, file= "Titanic_random_forest_prediction.csv", row.names=FALSE)

# Random forest Accuracy Result: 76.08%
```

# Conclusion:

- List of features are found association with whether passenger survive are following:
  (Sex, Pclass, Fare, Age, Embarked, SibSp)
  
- Being female greatly increase chance of survive
- Higher economical class greatly increase chance of survive
- Higher Ticket Fare slightly increase chance of survive
- Younger Age slightly increase the chance of survive
- Embarked at Port Cherbourg moderately increase the chance of survive
- Less sibing slightly increase chance of survive
